{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f57d1659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "021922d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vocabulary(root_dir):\n",
    "  word_list = []  #create a list to contain all the words\n",
    "  emails = [os.path.join(root_dir,f) for f in os.listdir(root_dir)] # os.listdir can output a list of emails names that folders contain\n",
    "  for mail in emails:  \n",
    "    with open(mail) as m:  #with - as - means assigns open(mail)'s value to m, after the end of the program, automatically exit\n",
    "      for line in m:\n",
    "        words = line.split() #The default separator is space. Separate the words in each line.\n",
    "        word_list += words\n",
    "  vocabulary = Counter(word_list)#count the number of occurence of string, and then return the value can be interpreted as a dictionary\n",
    "  clean_vocabulary = list(vocabulary)#transform vocabulary as a list type\n",
    "\n",
    "  for item in clean_vocabulary:\n",
    "    if item.isalpha() == False:#The isalpha() method checks if the string consists of only letters\n",
    "      del vocabulary[item]\n",
    "    elif len(item) == 1:#Checks whether the length of string is 1 \n",
    "      del vocabulary[item]\n",
    "  vocabulary = vocabulary.most_common(3000) #Most_common () lists the n most common elements and their number\n",
    "  return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee5f82eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(mail_dir):\n",
    "  files = [os.path.join(mail_dir,fi) for fi in os.listdir(mail_dir)]# os.listdir can output a list of emails names that folders contain\n",
    "  features_matrix = np.zeros((len(files),3000))#Return a new array with shape is length of files,3000\n",
    "  train_labels = np.zeros(len(files))#Return a new array with shape is length of files\n",
    "  count = 1;\n",
    "  documentN0 = 0;\n",
    "  for fil in files:\n",
    "    with open(fil) as fi: #with - as - means assigns open(fil)'s value to m, after the end of the program, automatically exit\n",
    "      for i, line in enumerate(fi): #Enumerate() method adds a counter to an iterable and returns it in a form of enumerating object. This enumerated object can then be used directly for loops or converted into a list of tuples using the list() method\n",
    "        if i ==2:\n",
    "          words = line.split() #split to get words\n",
    "          for word in words:\n",
    "            wordID = 0  #assign wordID to word in words\n",
    "            for i, d in enumerate(vocabulary):\n",
    "              if d[0] == word:\n",
    "                wordID = i\n",
    "                features_matrix[documentN0,wordID] = words.count(word) # create word frequency matrix\n",
    "      train_labels[documentN0] = 0;\n",
    "      filepathTokens = fil.split('/')\n",
    "      lastToken = filepathTokens[len(filepathTokens)-1]\n",
    "      if lastToken.startswith(\"spmsg\"): #the name of spam emails begins with spmsg\n",
    "        train_labels[documentN0] = 1;\n",
    "        count = count + 1\n",
    "     documentN0 = documentN0 + 1\n",
    "  return features_matrix, train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f767b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb07a301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading and processing emails from TRAIN and TEST folders\n",
      "Training Model using Gaussian Naibe Bayes algorithm .....\n",
      "Training completed\n",
      "testing trained model to predict Test Data labels\n",
      "Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = 'F:/lmu data/BSAN6070/CA02/train-mails'\n",
    "TEST_DIR = 'F:/lmu data/BSAN6070/CA02/test-mails'\n",
    "\n",
    "vocabulary = make_vocabulary(TRAIN_DIR) #call the function def make_vocabulary(root_dir)\n",
    "\n",
    "print (\"reading and processing emails from TRAIN and TEST folders\")\n",
    "features_matrix, labels = get_features(TRAIN_DIR)  #call the function def get_features(mail_dir)\n",
    "test_features_matrix, test_labels = get_features(TEST_DIR)\n",
    "\n",
    "model = GaussianNB() #use GaussianNB\n",
    "\n",
    "print (\"Training Model using Gaussian Naibe Bayes algorithm .....\")\n",
    "model.fit(features_matrix, labels)#Used to perform the training process\n",
    "print (\"Training completed\")\n",
    "print (\"testing trained model to predict Test Data labels\")\n",
    "predicted_labels = model.predict(test_features_matrix)\n",
    "print (\"Completed classification of the Test Data .... now printing Accuracy Score by comparing the Predicted Labels with the Test Labels:\")\n",
    "print (accuracy_score(test_labels, predicted_labels)) #compare the accuracy score for predicted labels. Accuracy score is just percentage of correct predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a2cec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
